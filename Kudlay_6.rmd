---
title: "Упражнение 6"
author: "Кудлай Яна"
date: "08 04 2021"
output: html_document
---

Задачи:

Примените указанный в варианте метод к набору данных по своему варианту (см. таблицу ниже). Не забудьте предварительно сделать из категориальных переменных факторы. Выберите оптимальную модель с помощью кросс-валидации. Выведите её коэффициенты с помощью функции coef(). Рассчитайте MSE модели на тестовой выборке.

Примените указанный в варианте метод к набору данных по своему варианту (см. таблицу ниже). Для модели:

Подогнать модель на всей выборке и вычислить ошибку (MSE) с кросс-валидацией. По наименьшей MSE подобрать оптимальное значение настроечного параметра метода (гиперпараметр λ или число главных компонент M).

Подогнать модель с оптимальным значением параметра на обучающей выборке, посчитать MSE на тестовой.

Подогнать модель с оптимальным значением параметра на всех данных, вывести характеристики модели функцией summary().

Сравните оптимальные модели, полученные в заданиях 1 и 2 по MSE на тестовой выборке. Какой метод дал лучший результат? Доля тестовой выборки: 50%.

## Вариант 16

Данные College {ISLR}:

Accept - Количество принятых заявок;

Private - Фактор с уровнями Нет и Да, указывающий частный или государственный университет;

Apps - Количество полученных заявок;

F.Undergrad - Количество студентов очной формы обучения

Top25perc - - Процент новых студентов из лучших 25% H.S. класс;

P.Undergrad - Количество студентов-заочников

Books - Расчетные балансовые затраты

PhD - Пкт. факультета с докторскими степенями

S.F.Ratio - Соотношение студентов и преподавателей

Expend - Расходы на обучение в расчете на одного студента

```{r setup, include=FALSE}
# Загрузка пакетов
library('knitr')             # Пакет для генерации отчёта
library('ISLR')              # Набор данных College
library('leaps')             # Функция regsubset() - отбор оптимального подмножества переменных
library('pls')               # Частный метод наименьших квадратов - pls()

knitr::opts_chunk$set(echo = TRUE)
```


```{r}
my.seed <- 1

# Загрузка данных College
data('College')
# Переводим дискретные количественные переменные в факторы
College$Peivate <- as.factor(College$Private)

College <- College[, c(1:3, 5:7, 10,  12, 14, 16)]

```



```{r}
# Размерность данных
dim(College)
```


Считаем число пропусков в данных и убираем их.
```{r}
# Считаем пропуски
sum(is.na(College))
```

## Задача № 1

# Отбор оптимального подмножества


```{r}
# подгоняем модели с сочетаниями предикторов до 8 включительно
regfit.full <- regsubsets(Accept ~ ., College)
summary(regfit.full)
```

```{r}
# подгоняем модели с сочетаниями предикторов до 19 (максимум в данных)
regfit.full <- regsubsets(Accept ~ ., College, nvmax = 9)
reg.summary <- summary(regfit.full)
reg.summary
```

```{r}
# структура отчёта по модели (ищем характеристики качества)
names(reg.summary)
```

```{r}
# R^2 и скорректированный R^2
round(reg.summary$rsq, 3)
```

```{r}
# на графике
plot(1:9, reg.summary$rsq, type = 'b',
     xlab = 'Количество предикторов', ylab = 'R-квадрат')
# сода же добавим скорректированный R-квадрат
points(1:9, reg.summary$adjr2, col = 'red')
# модель с максимальным скорректированным R-квадратом
which.max(reg.summary$adjr2)

### 7
points(which.max(reg.summary$adjr2), 
       reg.summary$adjr2[which.max(reg.summary$adjr2)],
       col = 'red', cex = 2, pch = 20)
legend('bottomright', legend = c('R^2', 'R^2_adg'),
      col = c('black', 'red'), lty = c(1, NA),
      pch = c(1, 1))

```

```{r}
# C_p
reg.summary$cp

# число предикторов у оптимального значения критерия
which.min(reg.summary$cp)

### 7
# график
plot(reg.summary$cp, xlab = 'Число предикторов',
     ylab = 'C_p', type = 'b')
points(which.min(reg.summary$cp),
       reg.summary$cp[which.min(reg.summary$cp)], 
       col = 'red', cex = 2, pch = 20)
```

```{r}
# BIC
reg.summary$bic

# число предикторов у оптимального значения критерия
which.min(reg.summary$bic)

### 6
# график
plot(reg.summary$bic, xlab = 'Число предикторов',
     ylab = 'BIC', type = 'b')
points(which.min(reg.summary$bic),
       reg.summary$bic[which.min(reg.summary$bic)], 
       col = 'red', cex = 2, pch = 20)
```


```{r}
# метод plot для визуализации результатов
?plot.regsubsets
plot(regfit.full, scale = 'r2')
plot(regfit.full, scale = 'adjr2')
plot(regfit.full, scale = 'Cp')
plot(regfit.full, scale = 'bic')
# коэффициенты модели с наименьшим BIC
round(coef(regfit.full, 6), 3)
```

Нахождение оптимальной модели при помощи метода перекрёстной проверки

k-кратная кросс-валидация

```{r}
# Отбираем 10 блоков наблюдений
k <- 9
set.seed(my.seed)
folds <- sample(1:k, nrow(Auto), replace = T)

# Заготовка под матрицу с ошибками
cv.errors <- matrix(NA, k, 9, dimnames = list(NULL, paste(1:9)))

predict.regsubsets = function(object, newdata, id, ...) {
    form = as.formula(object$call[[2]])
    mat = model.matrix(form, newdata)
    coefi = coef(object, id = id)
    mat[, names(coefi)] %*% coefi}

# Заполняем матрицу в цикле по блокам данных
for (j in 1:k){
    best.fit <- regsubsets(Accept ~ ., data = College[folds != j, ],
                           nvmax = 9)
    # Теперь цикл по количеству объясняющих переменных
    for (i in 1:9){
        # Модельные значения Accept
        pred <- predict(best.fit, College[folds == j, ], id = i)
        # Вписываем ошибку в матрицу
        cv.errors[j, i] <- mean((College$Accept[folds == j] - pred)^2)
    }
}

# Усредняем матрицу по каждому столбцу (т.е. по блокам наблюдений), 
# Чтобы получить оценку MSE для каждой модели с фиксированным 
# Количеством объясняющих переменных
mean.cv.errors <- apply(cv.errors, 2, mean)
round(mean.cv.errors, 0)
```







```{r}

# На графике
plot(mean.cv.errors, type = 'b')
points(which.min(mean.cv.errors), mean.cv.errors[which.min(mean.cv.errors)],
       col = 'red', pch = 20, cex = 2)
```

```{r}
# Перестраиваем модель с 7 объясняющими переменными на всём наборе данных
reg.best <- regsubsets(Accept ~ ., data = College, nvmax = 7)
round(coef(reg.best, 7), 3)

```
## Задачa № 2

# Регрессия на главные компоненты

```{r}
# Кросс-валидация
set.seed(2)
pcr.fit <- pcr(Accept ~ ., data = College, scale = T, validation = 'CV')
summary(pcr.fit)
```

```{r}
# График ошибок
validationplot(pcr.fit, val.type = 'MSEP')
```


Подбор оптимального М: кросс-валидация на обучающей выборке

```{r}
set.seed(my.seed)
x <- model.matrix(Accept ~ ., College)[, -1]
train <- sample(1:nrow(x), nrow(x)/2)
test <- -train
y <- College$Accept
y.test <- y[test]
pcr.fit <- pcr(Accept ~ ., data = College, subset = train, scale = T, validation = 'CV')
validationplot(pcr.fit, val.type = 'MSEP')
```


```{r}
# MSE на тестовой выборке
pcr.pred <- predict(pcr.fit, x[test, ], ncomp = 9)
round(mean((pcr.pred - y.test)^2), 0)
## [1] 324568
# Подгоняем модель на всей выборке для М = 9
# (Оптимально по методу перекрёстной проверки)
pcr.fit <- pcr(y ~ x, scale = T, ncomp = 9)
summary(pcr.fit)
```


```{r}
# MSE на тестовой выборке с 6 объясняющими переменными (отбор оптимального подмножества)
opt.test <- predict(best.fit, College[test, ], id = 6)
opt.mse.test <- round(mean((opt.test - y.test)^2), 0)

# MSE на тестовой выборке (регрессия на главные компоненты)
regres.test <- predict(pcr.fit, x[test, ], ncomp = 9)
regres.mse.test <- round(mean((pcr.pred - y.test)^2), 0)

MSE.test <- rbind(opt.mse.test, regres.mse.test)
row.names(MSE.test) <- c('MSE (отбор оптимального подмножества)', 'MSE (регрессия на главные компоненты)')
kable(MSE.test)
```

MSE при отборе оптимального подмножества $=	382595$

MSE регрессии на главные компоненты	$= 390585$

стандартная ошибка MSE при отборе оптимального подмножества меньше, чем MSE регрессии на главные компоненты. Модель, построенная при отборе отпимаольного подмножесва считается лучшей.